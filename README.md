<<<<<<< homework_2

#  <a href="https://www.kaggle.com/code/anchsemen/gan-hw">**Homework_2 Имплементация GAN**</a>


### **Используемый датасет:** 
Для данной работы использовался датасет <a href="https://www.kaggle.com/datasets/jessicali9530/celeba-dataset">Celeba</a>, в котором находится свыше 200 тысяч изображений знаменитостей.

### **Цель эксперимента:** 
Имплементация и попытка достичь сходимости GAN. 

### **Идея эксперимента:**
Применить новую архитектуру генератора, заменяя сверточные слои на CSPup блоки, использовать дискриминатор как у DCGAN, и проверить сходимость сети на датасете CelebA, для которого уже подтверждена сходимость DCGAN, путем исследования различных гипотез, такие как применение регуляризации, изменение архитектуры сети, и т.п.

**Описание CSPupBlock:** CSPupBlock представляет собой модификацию CSP block из архитектуры Scaled YOLOv4. В CSPupBlock происходит следующее:

<img src=CSPupBlock.png>

При обучении GAN без проверки гипотез, получается следующий результат. Как видно по графику loss функций ни у генератора ни у дискриминатора не получается достичь сходимости за 5 эпох. И в целом, loss дискриминатора не максимизируется, но loss генератора со скачками минимизируется, но этого не достаточно. Получается что-то минимально похожее на лица, но это не тот результат, который хочется получить.

<img src=D_loss&G_loss_epochs5.png>
<img src=results_epochs5.png>

Со всеми графиками loss функций можно ознакомиться <a href="https://wandb.ai/anch-semen/HW2_GENmodels?nw=nwuseranchsemen">здесь</a>.

### **0 гипотеза**:
Не пробовать изменять архитектуру GAN, а увеличить количество эпох обучения в базовой архитектуре до 20. 

**Результаты 0 гипотезы:** Результаты лучше, чем на 5 эпохах (лица более выражены), но все равно видно по графикам loфss функций, что хорошей сходимости не наблюдается.  

<img src=D_loss&G_loss_hyp0epochs20.png>
<img src=results_hyp0epochs20.png>

### **1 гипотеза**:
Как было написано в <a href="https://arxiv.org/ftp/arxiv/papers/2006/2006.05132.pdf">статье</a>, воспользоваться:
1. Использовать Batch Normalization
2. Вместо активации ReLU применить Leaky-ReLU

**Результаты 1 гипотезы:** При сравнении результатов работы GAN на протяжении 5 эпох без применения улучшений и с использованием методов Batch Normalization и Leaky-ReLU, мы замечаем некоторое улучшение в качестве результатов. Однако, все еще отсутствует явная сходимость генератора и дискриминатора. Поэтому переходим

<img src=D_loss&G_loss_hyp1epochs5.png>
<img src=results_hyp1epochs5.png>

### **2 гипотеза**:
1. Увеличим в 2 раза batch_size
2. Применим L2-регуляризацию к генератору и дискриминатору

**Результаты 2 гипотезы:** В данном случае мы наблюдаем mode collapse в работе генератора, что негативно сказывается на обучении всей модели GAN. Этот режим характеризуется тем, что генератор производит только ограниченное разнообразие изображений, не способное отобразить полный спектр данных обучения. Такое поведение генератора отрицательно влияет на эффективность обучения модели, приводя к плохим результатам.

<img src=D_loss&G_loss_hyp2epochs5.png>
<img src=results_hyp2epochs5.png>

### **3 гипотеза**: 
1.label smoothing
2. lr Disc = 0.0003 lr Gen = 0.0008
3. Применим вместо сигмоиды гиперболический тангенс на последнем слое генератора

**Результаты 3 гипотезы:** Возник mode collapse в конце обучения, но видно как хорошо сходятся loss'ы генератора и дискриминатора. Данная архитектура показывает хорошую генерацию лиц. 

<img src=D_loss&G_loss_hyp3epochs5.png>
<img src=results_hyp3epochs5.png>

**Выводы:** Архитектура, описанная в третьей гипотезе, показала наилучшие результаты среди всех рассмотренных. Хотя наблюдался некоторый mode collapse, который приводит к ограниченному разнообразию генерируемых изображений, думаю что при дальнейшем улучшении данной архитектуры можно добиться значительного прогресса.
=======
Кирсанов Семен Олегович

Глубокие генеративные модели

#  <a href="https://colab.research.google.com/drive/1nu7Ejtk0n-DeQCfqrlkSLIMLW8duCSPx?usp=sharing">**Homework_1**</a>

## **1 задача:** Байесовский генератор стилей

**Используемый датасет:** 
1. Для текстового генератора использовался словарь из 28 различных вариантов стиля персонажа (прическа, цвет волос, аксессуар и т.д.) 
2. Для работы с изображениями использовалось 11 изображений аватаров с различными стилями (прическа, цвет волос, аксессуар и т.д.)

**Цель эксперимента:** Генерация стилей (первоначально текстовый, далее аватаров)

**Идея эксперимента:** С помощью формулы MLE: $\hat{\theta} =  \underset{\theta}{\text{argmax}} \ \mathcal{L}(\theta | \textbf{X})$ и формулы Байеса: $p(\textbf{x}) = p(x_1, ..., x_k) =  \prod\limits_{k=1}^K (x_k | x_1, ..., x_{k-1})$ создать генератор стилей (в текстовом случае используя аддитивное сглаживание $\hat{\theta_j} = \frac{n_j+1}{N+d}$, в случае работы с пикселями используя полиномиальную модель $\hat{\theta_j} = \frac{n_j}{N}$). 

**Результаты эксперимента**: смотреть в репозитории (result_1, ..., result_5) 

**Выводы:** По формуле Байеса генерация новых аватаров выходит плохо, т.к. каждый пиксель зависит от пикселей, которые находятся рядом (каждая часть тела/каждый акссесуар по пиксельно должен находиться в своем месте), а вместо этого происходит некоторый «расплыв» изображений.

## **2 задача:** Автоэнкодер

<a href="https://drive.google.com/file/d/1DHuQ3DBsgab6NtZIZfAKUHS2rW3-vmtb/view?usp=sharing">**Используемый датасет**</a>

**Цель эксперимента:** С помощью автоэнкодера классифицировать изображения лунок на производстве (есть пролив/нет пролива)

**Идея эксперимента:** Обучить автоэнкодер на изображениях лунок без проливов, далее посмотреть ошибку MSE на изображениях без проливов / с проливами и определить threshold для классификации изображений из тестовой выборки. 

**Результаты эксперимента**: 

График MSE для различных сэмплов из обучающей выборки и выборки с проливами, а также со значением threshold (автоэнкодер с занятия):

<img src=MSE_samples(train-proliv-lesson).png>

График MSE для различных сэмплов из обучающей выборки и выборки с проливами, а также со значением threshold (автоэнкодер с 5ю линейными слоями):

<img src=MSE_samples(train-proliv-another).png>

<a href="https://wandb.ai/anch-semen/HW1_GENmodels?nw=nwuseranchsemen">Графики loss функции в wandb</a>;

1. Для автоэнкодера с занятия: True Positive Rate = 0.752 True Negative Rate =  0.747, что значит с threshold $\approx 0.56 \cdot max(mse proliv) \approx$ 0.00658  классификатор достаточно хорошо распознает лунки с проливами и без проливов.
2. Для автоэнкодера с 5ю линейными слоями: True Positive Rate = 0.76 True Negative Rate = 0.66 с учетом такого же threshold $\approx$ 0.00658, что значит такая структура автоэнкодера хуже распознает лунок без пролива, но возможно при использовании другого порогового значения может помочь стабилизировать показатели. 

Если использовать для автоэнкодера с 5ю линейными слоями threshold $\approx 0.6 \cdot max(mse proliv) \approx$ 0.00699, то True Positive Rate = 0.736 True Negative Rate = 0.731, но это все равно по результатом не лучше, чем у автоэнкодера с занятия. 

**Выводы:** На основе представленных результатов, можно сделать вывод, что автоэнкодер с двумя линейными слоями и выбранным порогом для классификации успешно различает различные лунки, чем автоэнкодер с 5 слоями (при условии фиксации порогового значения) Однако стоит также рассмотреть альтернативные варианты автоэнкодера с другим количеством слоев, поскольку это может привести к улучшению работы классификатора. Либо подобрать threshold для какой-то конкретной задачи (для поиска именно проливов, но слегка пренебречь обычными лунками) 
>>>>>>> main
