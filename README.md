Кирсанов Семен Олегович

Глубокие генеративные модели

#  <a href="https://colab.research.google.com/drive/1nu7Ejtk0n-DeQCfqrlkSLIMLW8duCSPx?usp=sharing">**Homework_1**</a>

## **1 задача:** Байесовский генератор стилей

**Используемый датасет:** 
1. Для текстового генератора использовался словарь из 28 различных вариантов стиля персонажа (прическа, цвет волос, аксессуар и т.д.) 
2. Для работы с изображениями использовалось 11 изображений аватаров с различными стилями (прическа, цвет волос, аксессуар и т.д.)

**Цель эксперимента:** Генерация стилей (первоначально текстовый, далее аватаров)

**Идея эксперимента:** С помощью формулы MLE: $\hat{\theta} =  \underset{\theta}{\text{argmax}} \ \mathcal{L}(\theta | \textbf{X})$ и формулы Байеса: $p(\textbf{x}) = p(x_1, ..., x_k) =  \prod\limits_{k=1}^K (x_k | x_1, ..., x_{k-1})$ создать генератор стилей (в текстовом случае используя аддитивное сглаживание $\hat{\theta_j} = \frac{n_j+1}{N+d}$, в случае работы с пикселями используя полиномиальную модель $\hat{\theta_j} = \frac{n_j}{N}$). 

**Результаты эксперимента**: смотреть в репозитории (result_1, ..., result_5) 

**Выводы:** По формуле Байеса генерация новых аватаров выходит плохо, т.к. каждый пиксель зависит от пикселей, которые находятся рядом (каждая часть тела/каждый акссесуар по пиксельно должен находиться в своем месте), а вместо этого происходит некоторый «расплыв» изображений.

## **2 задача:** Автоэнкодер

<a href="https://drive.google.com/file/d/1DHuQ3DBsgab6NtZIZfAKUHS2rW3-vmtb/view?usp=sharing">**Используемый датасет**</a>

**Цель эксперимента:** С помощью автоэнкодера классифицировать изображения лунок на производстве (есть пролив/нет пролива)

**Идея эксперимента:** Обучить автоэнкодер на изображениях лунок без проливов, далее посмотреть ошибку MSE на изображениях без проливов / с проливами и определить threshold для классификации изображений из тестовой выборки. 

**Результаты эксперимента**: 

График MSE для различных сэмплов из обучающей выборки и выборки с проливами, а также со значением threshold (автоэнкодер с занятия):

<img src=MSE_samples(train-proliv-lesson).png>

График MSE для различных сэмплов из обучающей выборки и выборки с проливами, а также со значением threshold (автоэнкодер с 5ю линейными слоями):

<img src=MSE_samples(train-proliv-another).png>

<a href="https://wandb.ai/anch-semen/HW1_GENmodels?nw=nwuseranchsemen">Графики loss функции в wandb</a>;

1. Для автоэнкодера с занятия: True Positive Rate = 0.752 True Negative Rate =  0.747, что значит с threshold $\approx 0.56 \cdot max(mse proliv) \approx$ 0.00658  классификатор достаточно хорошо распознает лунки с проливами и без проливов.
2. Для автоэнкодера с 5ю линейными слоями: True Positive Rate = 0.76 True Negative Rate = 0.66 с учетом такого же threshold $\approx$ 0.00658, что значит такая структура автоэнкодера хуже распознает лунок без пролива, но возможно при использовании другого порогового значения может помочь стабилизировать показатели. 

Если использовать для автоэнкодера с 5ю линейными слоями threshold $\approx 0.6 \cdot max(mse proliv) \approx$ 0.00699, то True Positive Rate = 0.736 True Negative Rate = 0.731, но это все равно по результатом не лучше, чем у автоэнкодера с занятия. 

**Выводы:** На основе представленных результатов, можно сделать вывод, что автоэнкодер с двумя линейными слоями и выбранным порогом для классификации успешно различает различные лунки, чем автоэнкодер с 5 слоями (при условии фиксации порогового значения) Однако стоит также рассмотреть альтернативные варианты автоэнкодера с другим количеством слоев, поскольку это может привести к улучшению работы классификатора. Либо подобрать threshold для какой-то конкретной задачи (для поиска именно проливов, но слегка пренебречь обычными лунками) 
